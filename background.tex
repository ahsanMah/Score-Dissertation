\chapter{Background and Prior Work}

\section{Score Matching}
Recall that a score is defined as the gradient of the log probability density, with respect to the data. Conceptually, a score is a vector field that points in the direction where the log density grows the most. 
\tempcit{Hyvernan} introduced score matching as a means of computing the parameters of an unnormalized probability density models. The authors proved the remarkable property that learning the score involves the gradient of the score function itself as shown in Equation~\ref{eq:implicit_sm}. I will follow the naming scheme used in \tempcite{Vincent} and name this objective as Implicit Score Matching.

\begin{align}
\label{eq:implicit_sm}
    J_{ISM}(\theta) &= \mathbb{E}_{p(x)} \frac{1}{2} \s{ \norm{s_\theta(x) - \nabla_x \log p(x) }^2 } \\
    &= \mathbb{E}_{p(x)} \s{ \norm{s_\theta(x)}^2 + \sum^{d}_{i=1}{\partial{x_{i}} s(x_{i}) } }
\end{align}


\subsection{Denoising Score Matching}

\tempcite{Vincent} formalized a connection between denoising autoencoders and score matching, and proposed the denoising score matching (DSM) objective.

The authors noted how \tempcite{Hyvernan} had suggested the possibility of an alternate score matching objective; one that was based on regressing against the data gradients of a Parzen window density estimator.

\begin{align}
\label{eq:explicit_sm}
    J_{ESM}(\theta) &= \mathbb{E}_{q_{\sigma}(x)} \frac{1}{2} \s{ \norm{s_\theta(x) - \nabla_x \log q_{\sigma}(x) }^2 }
\end{align}

\tempcit{Vincent} showed that under certain regularity conditions
\footnote{For any window size $\sigma > 0$, the kernel $q_{\sigma}$ is differentiable, converges to 0 at infinity, and has a finite gradient norm},
the Parzen window based objective is equivalent to the original objective proposed by \tempcite{Hyvernan} in \eqref{eq:implicit_sm}

Taking it one step further, assume the Parzen density estimate is chosen to estimate the joint density of clean and corrupted samples $(x, \tilde{x})$ i.e. $q_{\sigma}(x, \tilde{x}) = q_{\sigma}(x | \tilde{x} ) p(x) $. Thus, the DSM objective is simply:

\begin{align}
\label{eq:denoising_sm}
    J_{DSM}(\theta) &= \mathbb{E}_{q_{\sigma}(x, \tilde{x})} \frac{1}{2} \s{ \norm{s_\theta(\tilde{x}) - \nabla_{\tilde{x}} \log q_{\sigma}(x | \tilde{x}) }^2 }
\end{align}

DSM mitigates the need for computing second order gradients as is the case for \ref{eq:implicit_sm}. Furthermore, if $q_{\sigma}$ is set as the Gaussian kernel, then $\nabla_x \log q_{\sigma}(\tilde{x}) = \frac{(x - \tilde{x}}{\sigma})$. One can now see the connection between score matching and the denoising autoencoder objective, when using a Gaussian kernel with a fixed scale.

I emphasize that while the original paper and many subsequent works \tempcite{song} use the Gaussian distribution in DSM, the proof holds for \textit{any} differentiable noise distribution.
I will make use of this fact when deriving a score matching objective for categorical data in Chapter~\ref{ch:gnsm}.

\subsection{Noise Conditioned Score Matching}

\subsection{Connecting Score Matching to Diffusion Models}
Recently, \tempcite{song 2021} described a connection between noise-conditioned score matching and diffusion models \tempcite{diffusion-jho}. The connection is presented under the lens of generative modeling, and provides a unifying framework for Markov-based and continuous-time diffusion models based on estimating the scores. 
For the purposes of this research, we focus on the relaxation of the discretized nature of noise conditioned score matching.

\subsubsection*{Continuous-Time Score Matching}


\section{Anomaly Detection}

This section provides a summary of the relevant methodologies in anomaly detection.

\subsection{Likelihood-based}
\begin{itemize}
    \item Density 
    \item Energy
    \item One-class objectives
\end{itemize}

\subsection{Restoration based}

\subsection{Out-of-Distribution Detection}
A considerable amount of effort has gone into detecting out-of-distribution (OOD) data samples, especially under the lens of classification models. Thus, there is a class of methods that augment existing classifiers to better detect OOD input samples, rather than training an unsupervised detector from scratch. Perhaps the seminal work in this area was done by \cite{Hendrycks2019}. The authors were the first to significantly highlight the domain-shift discrepancy exhibited by a range of deep learning models, and established an experimental test-bed that has served as a template for subsequent OOD work. They posited that OOD samples are likely to be assigned low probabilities and purported the thresholding of softmax probabilities from well-trained classifiers to detect in-domain samples. \cite{Liang2017} propose ODIN as a post-hoc method that utilizes a pretrained network to reliably separate OOD samples from the inlier distribution. They achieve this via a two-step procedure. First, the input image is perturbed in the gradient direction of the highest (inlier) softmax probability. Next, the softmax outputs of the classifier are scaled by a temperature, which is determined via a held out test set. While the authors report good performance, ODIN's effectiveness depends heavily on tuning the hyperparameters, namely the gradient step and the temperature. \cite{devries2018learning} improved upon \cite{Hendrycks2019} (and somewhat upon ODIN) by training networks to produce confidence estimates alongside softmax probabilities for outlier thresholding. Concurrently, \cite{Lee2018} jointly trained a GAN alongside a classifier to generate realistic OOD examples. This required an additional OOD set during training, and the resulting classifiers were unable to generalize to unseen datasets.


\subsection{Methods Common to Medical Imaging}
