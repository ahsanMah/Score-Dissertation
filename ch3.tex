\chapter{Localizing Anomalies via Spatial-MSMA}
\label{ch:localizing}

Generic anomaly detection methods operate on the full input and make binary predictions on whether a sample is anomalous. They do not, however, provide information about the input components that led to that assessment. It is often desirable to identify the specific regions within an image that are contributing to its atypicality. Such localization allows for increased model interpretability as well as directing future investigation. 

For instance, in healthcare, the ability to interpret a model's prediction empowers medical practitioners to visually corroborate the identified regions of interest. Interpretation may also pave the way for novel insights into the disease. Furthermore, localizing anomalies enables targeted diagnosis and intervention planning based on the factors contributing to the detected outlier.

Another industry where anomaly detection has critical real-world value, is manufacturing~\cite{Bergmann_2019_CVPR}. Supply chain industries often need to automate defect identification to reduce operational costs and time requirements. This is typically accomplished through image-based anomaly detection. As the type of defects that can emerge in production are unknown, these systems utilize unsupervised models to enable broad detection. Additionally,  the models are tasked to output pixel-level segmentations to help manufacturers design solutions to remediate the defects. Although many unsupervised anomaly localization methods have been proposed in recent years, it still remains an active area of research~\cite{liu2024deep}. 

This chapter will introduce Spatial-MSMA: an extended version of MSMA with localization capabilities. Note that the benefits of localization are twofold. First, it allows the possibility of detecting physical anomalies. For example, Spatial-MSMA has the capabilities of highlighting brain regions with lesions even though it was never trained with labeled data. Second, localization enables exploratory insights, gained through the interpretation of heatmaps. The two benefits are orthogonal with respect to one another and significantly expand the use-case for MSMA.

\section{Existing Techniques for Anomaly Localization}

\subsection*{Reconstruction based Approaches}
Reconstruction-based anomaly detectors are trained to produce typical counterparts (so-called reconstructions) of anomalous images. The methods may take some form of a deep autoencoder~\cite{dae-kascenas22a,baur2021}, trained with a reconstruction error objective such as mean squared error. At test time, the models are presumed to output an anomaly-free image, with the \textit{reconstruction error} as the metric of atypicality. A known drawback of these models is the lack of specificity in their detection. As no reconstruction is pixel-perfect (especially in terms of image intensities), the output error maps have significant false-positives~\cite{baur2021}. Another drawback of autoencoders is that as their reconstruction abilities improve, their anomaly detection capabilities decrease as the models are better at reconstructing the anomalies.

\subsection*{Generative Modeling based Approaches}
Some methods propose to employ generative models for removing anomalies via imputation or ``restoration''~\cite{schlegl2019f,pmlr-v102-you19a}. Imputation-based approaches utilize masking strategies to mask out certain regions of the image and use the generative model to in-paint \textit{only} the masked regions. Restoration-based approaches do not use any masks and instead modify the entire image, using the original image as the starting point in the sampling procedure.

Recently, owing to the success of score-based diffusion models, much of the research has focused on using diffusion models as their generative model (replacing GANs of yesteryear)~\cite{wyattAnoddpmAnomalyDetection2022,pinaya2022fast,liuUnsupervisedOutofDistributionDetection2023,behrendtPatchedDiffusionModels2023}. All of these models provide slight modifications to the diffusion sampling process, and start the generation process from an input image rather than random noise. The sampling process starts by adding noise to the input image and iteratively denoises the sample to generate an anomaly-free counterpart of the original image. Once the cleaned sample is generated, a voxel-wise difference between the input and its anomaly-free counterpart is used as the anomaly score. The main differentiating factor between these methods are the hyperparameters used for training and the sampling strategies used during inference. 

\subsection*{Feature Embedding based Approaches}
% To circumvent the drawbacks of reconstruction errors in the image space, feature embedding based approaches compute recionstructions erroin the \textit{embedding} space.
Some methods aim to detect anomalies in a learned embedding space. The feature embeddings are computed by a neural network trained on the typical samples. At test time, it is assumed that the model will output feature embeddings that are \textit{close} to the feature embeddings of the training population if the sample is an inlier and \textit{away} otherwise. A popular method in this category is the Student-Teacher architecture anomaly detector by~\cite{bergmann2020uninformed}. In this setting, we have two models: a high parameter-count Teacher network and low parameter-count Student network. The student model is considered to be a ``weaker" version of the Teacher, and is trained using neural network distillation techniques. It is assumed that the Student model will fail to generalize to unseen datasets, producing a discrepancy between the teacher's features and that of the student. This discrepancy is used to produce an anomaly score.

\subsection*{Attribution based Approaches}
Certain techniques draw on the insights of interpretability research. The task is to identify features of the data that contribute to the model's output. The identified features are often assigned a score relative to their importance, as determined by the rules of the interpretation technique. Examples of such methods include SHAP~\cite{NIPS2017_7062}, Saliency Maps~\cite{Simonyan2013DeepIC}, and GradCAM~\cite{gradcam}.

SHAP (SHapley Additive exPlanations) is a game-theoretic approach to explain the output of any machine learning model. SHAP values attribute the prediction of an instance to the different features, highlighting the positive or negative impact of each feature. Saliency Maps are a visualization technique that highlight areas of an input image that most influence the output of a network. The saliency map is computed by taking the gradient of the output with respect to the input image. Areas with high gradient values correspond to regions in the input that have a significant impact on the model's prediction. GradCAM (Gradient-weighted Class Activation Mapping) is an extension of saliency maps that computes gradients with respect to feature vectors of an image rather than the image itself.

All of the mentioned attribution-based approaches aim to identify the features or input regions that contribute most to the model's predictions. This information can be used for anomaly detection, as it can localize the patches that lead a model to classify an instance as an anomaly.

\section{Spatial-MSMA: Incorporating Spatial Information into MSMA}
The basic assumption of MSMA is that inliers will occupy distinct regions in the score-norm space. At test time, we ask the question: Does the given sample belong to the inliers? MSMA consequently estimates the likelihood of a sample belonging to the inlier region in the score-norm space. Up until this chapter we have looked at the data samples holistically, i.e. we considered the entire set of features available to us (e.g. all the pixels in an image). 

However, MSMA is also amenable for \textit{subsets} of features. For instance, we may divide an image into patches and consider the score-norms of each patch independently. Now, we can ask the question: Does this \textit{patch} belong to the inliers? As before, MSMA will output a likelihood estimate of a test patch belonging to the inliers, but this time \textit{only} considering information present at the given patch location.

It is possible to naively extend MSMA to consider patches. One can decompose the image into a regular grid, and train an independent MSMA model for each grid location. One may even reduce computational costs by running training/inference in parallel for each patch location. However, while this approach is straightforward, it has some limitations.

\subsection*{Image Patches are Not Independent of Each Other}
Namely, we cannot ignore \textit{spatial locality}: the notion that neighbouring image patches are highly correlated. Furthermore, even patches which are spatially apart may depend on each other. Consider an image of a face.
% Observing the patches corresponding to the left eye gives us rich information about what we may observe in regions distal to the left eye.
Observing patches of the left eye gives us rich information about what we may observe in the location of the \textit{right} eye, even if the location of the right eye is distal to the left.
One can leverage this information to reason about the typicality of a queried patch. For instance, observing a brown-colored right eye is typical. However, observing a brown colored right eye \textit{given} a black-colored left eye, is atypical.

\subsection*{Modeling Conditional Likelihoods}
Following the motivation above, one can employ a conditional model where in addition to the contents of a patch, its position and surrounding context are also taken into account.As such, I posit to use a conditional likelihood model as the basis of my patch-based anomaly detector.

Concretely, the model will be conditioned on the patch position and the image features. Let $ s_p = \{s(x_p)\}_{i=1}^{L}$ be the multi-scale score tensor for a given patch $x_p$ at location $p$, belonging to the image $x$. Let $h(x)$ are the feature vectors of the image $x$ computed by a convolutional network $h$. I propose to estimate the conditional likelihood model $p(s_p | p, h(x))$. As this model will output likelihoods of score-norms for each patch conditioned on the surrounding spatial information, the model is called Spatial-MSMA.

Spatial-MSMA uses a flexible class of likelihood estimators called normalizing flows introduced in Chapter~\ref{ch:background}. The patch locations are modeled via sinusoidal positional embeddings, commonly used in Transformer models~\cite{vaswani}. In order to capture global image context, the original image is passed through a convolutional network with a large receptive field. The resulting feature embeddings are concatenated with the positional embeddings and fed into the flow model as contextual information.

\section{Prototyping on 2D Images}

This section focuses on the task of segmenting anomalies in 2D images due to the availability of benchmark datasets and pretained models. A controlled experiment like this allowed me to refine the model architecture and compare Spatial-MSMA's performance to existing methodologies.

Most existing methods are trained and tested on the MvTec anomaly detection dataset~\cite{Bergmann_2019_CVPR}. This dataset focuses on industrial inspection and comprises of a set of defect-free training images and a test set of images with various kinds of manufacturing defects. The test set includes high resolution segmentation maps which allow us to validate the performance of the anomaly detection model. Note that the difficulty of this task stems from its unsupervised nature. At training time, the model will only see typical images and it cannot assume anything about the defects at the testing stage.

Similar to MSMA, Spatial-MSMA is trained in two stages. First, a score matching model is trained on the images and then the weights are frozen. Next, a likelihood model is trained on the score norms of the images. Unlike MSMA however, in Spatial-MSMA the likelihood model is trained on score norms of \textit{patches} rather than an score norms of an entire image.

\subsection*{Experiment Details}
To train the score-matching model, I finetuned a publicly available checkpoint~\footnote{\url{https://drive.google.com/file/d/1JInV8bPGy18QiIzZcS1iECGHCuXL6_Nz/view?usp=drive_link}} of a score-based diffusion model trained on the CIFAR-10 dataset. Next, a deep normalizing flow model is trained on the score norms for each patch, where the patch size is a fixed hyper parameter. The flow model receives the positional embeddings and the feature representations of the original image as conditioning vectors. Once the flow model is trained, we can evaluate it at every patch location in the image using a sliding-window. The resulting image is a likelihood heatmap, which is inverted to get the anomaly heatmap (negative log-likelihood).

For this experiment, the score model was trained on the \textit{Cables} class. To evaluate the anomaly detection performance, the results were compared to that of the original authors of the MvTec dataset~\cite{bergmann2020uninformed}. I compute the per-region overlap metric introduced by the same authors, which measures the overlap between connected components in the ground truth and the anomaly map for every threshold. Even without any hyperparameter tuning, Spatial-MSMA is able to outperform the baseline by 10\% for the same patch size on the Cables class (.741 PRO-AUC vs .671 PRO-AUC).


\section{Case Study: Lesion Detection in Volumetric Brain MRIs}
Following the encouraging results on the MvTec dataset, this section will consider the more challenging task of detecting anomalies in medical images. The purpose of this case study is to reflect a real world usecase: automatic detection and segmentation of pathologies. As this is a feasibility experiment, one needs to minimize confounding factors that can be introduced due to a distributional shift between the training and testing populations. Thus, the anomalies will be simulated on a held out inlier test set, ensuring that the introduced anomalies are the \textit{primary} factor differentiating the test set from the inlier population.

\subsection*{Experiment Details}
The model is trained on a population of typically developing adolescent brains, retrieved from the ABCD study~\cite{Casey2018adolescent}. We use both T1-weigthed and T2-weighted images. The images were downsampled to a pixel spacing of 2, cropped by the largest brain mask with some additional padding. The resulting 3D volume is of size 96x112x80. The anomalies were simulated using lesion simulator tool~\cite{Filho_2019}, available as the MSLesionSimulator extension~\footnote{https://www.slicer.org/wiki/Documentation/Nightly/Modules/MSLesionSimulator} of the Slicer3D software package~\cite{fedorov3DSlicerImage2012}. The lesion load parameter was set to 20 and the rest of the hyperparameters were kept at their default values. A post processing step was performed to enhance the lesion intensity by a factor of $1.5$.

The score-norms were retrieved from a diffusion model, using a 3D convolutional UNet-like architecture. I used the VESDE formulation, with 1000 timesteps. The minimum sigma was set to <MIN> and the maximum was computed from the maximum pairwise distance in the trianing set <MAX>. The model was trained for 1.5 million iterations. The batch size was doubled at roughly the half way point during training. This is a simple yet effective method proposed by~\cite{le2018dont}, to effectively anneal the learning rate without having to use a decay schedule. The authors also found that increasing the batch size also reduced the number of parameter updates required to reach the same test accuracies as the learning rate decay setting.

During inference, the voxel-wise anomaly scores are first brain masked followed by thresholding. The threshold is determined for each sample by searching for the threshold that gives the lowest symmetric mean surface distance between the ground truth and the post-threshold segmentation. Searching for a threshold like this is common practice in evaluating anomaly detectors~\cite{baur_deep_2019}. The segmentations are post-processed by removing connected components of size less than 3 voxels (using a connectivity of 1). The remaining segmentation mask is dilated via a disk of radius 1 as the structuring element. Note that this inference procedure is performed for all methods tested in the experiment.

\subsection*{Baseline Methodologies}

Spatial-MSMA was compared to a selection of models that encompass a broad range of anomaly detection methodologies that have been successfully used in the medical imaging field. Namely, the baselines represent reconstruction-based, generative-based, and interpretation-based methods.
% mention why feature embedding not present..?

For the reconstruction-based baseline, I chose an autoencoder model by~\cite{aelu2023} owing to its success on volumetric brain MRIs. The model uses a ResNet-like architecture is trained using a reconstruction objective based on a Mean Squared Error (MSE). The authors also provide a publicly available implementation. This method is denoted as AE in Table~\ref{lesion_results}.

Two generative-model based approaches were also included in the comparison. First is an imputation-based approach inspired by~\cite{liuUnsupervisedOutofDistributionDetection2023} which uses a checkerboard mask to in-paint different regions of the image (denoted as Inpaint in Table~\ref{lesion_results}). This method performs multiple runs of imputation, alternating the checkerboard pattern each time and computing the average error across all runs. Second is a restoration-based approach (denoted as Restoration in Table~\ref{lesion_results}), which first adds noise to the image and then invokes the sampling procedure of the diffusion model to iteratively generate the restored counterpart. Following~\cite{wyattAnoddpmAnomalyDetection2022}, the sampling procedure was initiated from 1/4th of the original timesteps. However, unlike~\cite{wyattAnoddpmAnomalyDetection2022}, I did not use Simplex noise during training/inference as recent research has shown that it may not be necessary (and sometimes detrimental)~\cite{kascenas2023}. 

Lastly, GradCAM was included as a representative of attribution-based approaches. Specifically, I used Guided-GradCAM~\cite{Selvaraju2016GradCAMVE} which combines saliency maps (with some modifications) and GradCAM to give superior results to vanilla GradCAM. The gradients were computed using the outputs of a non-spatial MSMA. Concretely, a GMM was trained on the whole-image score norms and the GradCAM gradients were computed using the negative likelihood estimates. This corresponds to computing voxel-wise attribution maps for an MSMA anomaly score. Thus, the method is denoted as GradCAM-MSMA in Table~\ref{lesion_results}.

\subsection*{Segementation Metrics for Analysis}
Similar to Section~\ref{cat-seg-study}, I chose mean surface distance (MSD), and the Hausdorff distance as the segmentation metrics to compare the results. These metrics compute the distance between the surfaces of the predictions and ground truth and are less biased towards over-segmentations compared to the more popular Dice score. Both distances are computed in a directed manner i.e. the distance is computed from the ground truth to the prediction. For Hausdorff distance, the 99-th percentile is used. In addition to distance metrics, component-wise metrics were also computed. Connected components were computed from the voxel-wise segmentation masks by considering an 8-connectivity-neighborhood (diagonals were included as neighbours). We assign a \textit{true positive} (TP) label to a component in the prediction which overlaps with any component in the ground-truth at any voxel location. Conversely, the absence of any overlap is used to keep a tally of the number of \textit{false positives} (FP). Table~\ref{lesion_results} reports the True Positive Rate (TPR = TP/(TP+FN)) and the Positive Predictive Value (PPV = TP/(TP+FP)). 

\subsection*{Results}

Table~\ref{lesion_results} reports the segmentation performance of all the methods tested. Note that due to the size of the lesions, the segmentation task was difficult for all models. However, Spatial-MSMA significantly outperforms the competition. Compared to baselines, Spatial-MSMA shows the lowest distance metrics. These metrics reflect the specificity of the model's segmentation capabilities. Lower distances imply that the models segmentations have tighter boundaries around the anomalies, compared to baselines. Conversely, the component-wise metrics reflect the sensitivity of the model to anomalous regions in the image, regardless of size. Spatial-MSMA shows excellent detection capabilities, evident by the $0.83$ TPR as well as the exceptionally high PPV of $0.96$ (recall that the maximum possible PPV is 1.0). This implies that Spatial-MSMA detects few false positives, an advantageous trait in anomaly detection.

\begin{table*}[!ht]
\centering
\begin{tabular}{lrr|rr}
{} &        99-HD~$\downarrow$~~&      MSD~$\downarrow$~~~~~&        TPR~$\uparrow$~~~~&             PPV~$\uparrow$~~~~~\\
\midrule
AE           &  12.27$\pm$~0.51 &  3.63$\pm$~0.35 &  0.44$\pm$~0.02 &  0.19$\pm$~0.01 \\
Inpaint      &  13.26$\pm$~0.50 &  3.71$\pm$~0.27 &  0.63$\pm$~0.02 &  0.50$\pm$~0.02 \\
Restoration  &   8.67$\pm$~0.53 &  2.68$\pm$~0.36 &  0.68$\pm$~0.02 &  0.17$\pm$~0.01 \\
GradCAM-MSMA &  12.68$\pm$~0.54 &  3.75$\pm$~0.37 &  0.43$\pm$~0.02 &  0.16$\pm$~0.01 \\
Spatial-MSMA &  \textbf{7.05~$\pm$~0.61} &  \textbf{2.10~$\pm$~0.43} &  \textbf{0.83~$\pm$~0.01} &  \textbf{0.96~$\pm$~0.01} \\
\end{tabular}

\caption{Segmentation metrics for lesion detection. Each model was trained on the inlier samples. Right column shows distance based metrics: 99th-percentile of the Hausdorff Distance (99-HD) and Mean Surface Distance (MSD). Right column shows component-wise metrics: True Positive Rate (TPR = TP/(TP+FN)) and Positive Predictive Value (PPV = TP/(TP+FP)). Spatial-MSMA significantly outperforms the baseline methodologies, especially when compared with component-wise metrics. }
\label{lesion_results}
\end{table*}

\section{Conclusion}
This chapter introduced Spatial-MSMA: an extension to MSMA that enables localization of anomalies. The key insight is to use a conditional likelihood model to learn the distribution of patch score norms, conditioned on the patch location and surrounding context. In my experiments, Spatial-MSMA succeeds at identifying anomalous regions in an image and shows significant performance improvements over baselines. While this chapter focused on experimentally verifying the capabilities of Spatial-MSMA using ground-truth data, the next chapter will investigate the data exploration capabilities of this approach.